---
layout: post
title: Problem Sheet 5
subtitle: Zachary Lim
---

1. First, I imported the necessary libraries, read the .csv files to a dataframe and then used `head` and `summary` to get a glimpse of the data

    ```R
    library(dplyr)
    library(ggplot2)
    library(tidyr)

    #import files to read
    mortality <- read.csv("mortality.csv")
    poverty <- read.csv("poverty.csv")
    
    #quick explorations
    #see the head
    head(mortality)
    head(poverty)
    
    #get a summary
    summary(mortality)
    summary(poverty)
    ```

2. Following which, I used pivot_longer to transform them to tidy data sets and cleaned the data by removing the "X" in front of the years to make them numeric. 

    ```R
    #pivot to make tidy
    mortality_tidy <- mortality %>% 
      pivot_longer(!country, names_to="year", values_to = "mrate") %>%
      mutate(year = as.numeric(gsub("X","",year)))
    poverty_tidy <- poverty %>% 
      pivot_longer(!country, names_to="year", values_to = "prate") %>%
      mutate(year = as.numeric(gsub("X","",year)))
    ```

3. I then combined the dataframes using `inner_join` since I wanted to retain only the rows that were found in both sets of data. I also used two columns "country" and "year" to ensure matching across countries and years. 

    ```R
    #join the dataframes to form data 
    data <- inner_join(mortality_tidy,poverty_tidy,by=c("country"="country","year"="year")) %>% na.omit(data)
    ```
4. The expected value of Y `E(Y)`, assuming unconditional expectation, would be the mean of Y. Similarly, `E(X)` would also be the mean of X. 

5. Following which, I calculated the correlation between *Y* and *X*.

    ```R
    #calculate the correlation
    corr <- cor(data$mrate,data$prate)
    corr 
    ## [1] 0.8107156
    ```

6. I then created the regression model and called the coefficients to estimate β. The value of β can be interpreted as, for every 1% increase in the poverty rate, the mortality rate increases by 1.379  (per thousand) 

    ```R
    #create the regression model
    reg <- lm(data$mrate ~ data$prate)       
    #show the coefficients 
    reg$coefficients
    ## (Intercept)  data$prate 
    ##    5.472942    1.379177
    ```

7. I then plotted the data, including the regression line.

    ```R
    #plot the model
    data %>% ggplot(aes(prate,mrate)) +
      geom_point(aes(color=factor(country)),show.legend = F) +
      geom_smooth(method = "lm") +
      theme_bw() +
      labs(title = "Linear Regression of Mortality Rate on Poverty Rate",
           x = "Poverty Rate (%)",
           y = "Infant Mortality Rate (per 1000)")
    ```

![image](https://user-images.githubusercontent.com/68678549/99757059-85994500-2b29-11eb-8f7e-2215e51dd9cc.png)

8. I then modelled the reverse, regressing poverty on mortality. We find that there appears to also be a positive correlation between mortality rate and poverty rate. 

    ```R
    #calculate the opposite regression model
    reg2 <- lm(data$prate ~ data$mrate)       
    #show the coefficients 
    reg2$coefficients
    ## (Intercept)  data$mrate 
    ##   8.1727704   0.4765594
    ```

9. In order to better understand the models, I called a summary of both models. 

    ```R
    #get summary of regression
    summary(reg)
    ## 
    ## Call:
    ## lm(formula = data$mrate ~ data$prate)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -83.095 -12.554  -0.739   7.996 177.340 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  5.47294    1.16893   4.682 3.14e-06 ***
    ## data$prate   1.37918    0.02779  49.621  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 27.83 on 1284 degrees of freedom
    ## Multiple R-squared:  0.6573, Adjusted R-squared:  0.657 
    ## F-statistic:  2462 on 1 and 1284 DF,  p-value: < 2.2e-16
    #get summary of 2nd regression
    summary(reg2)
    ## 
    ## Call:
    ## lm(formula = data$prate ~ data$mrate)
    ## 
    ## Residuals:
    ##    Min     1Q Median     3Q    Max 
    ## -63.66 -10.67  -3.37   8.78  62.61 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 8.172770   0.654359   12.49   <2e-16 ***
    ## data$mrate  0.476559   0.009604   49.62   <2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 16.36 on 1284 degrees of freedom
    ## Multiple R-squared:  0.6573, Adjusted R-squared:  0.657 
    ## F-statistic:  2462 on 1 and 1284 DF,  p-value: < 2.2e-16
    ```

As the famous aphorism goes, "All models are wrong, but some are useful". In this case, these models were useful in allowing us to better understand the relationship between poverty and mortality. We saw that a higher poverty rate generally results in an increased mortality rate. Looking at the p-values from the models, we see that this relationship is statistically significant. 

The model offered new information in allowing us to better understand the relationship between poverty and mortality, with an adjusted R^2 valued of 0.657. This suggests that in both instances, the explanatory variable X was able to explain 65.7% of the variance in Y. While the value of the R^2 is context dependent, we can conclude that this model is relatively useful in allowing us to predict the values of Y, given X. 

Some limitations of this model is a lack of validation. To better gauge the usefulness of the model, we could have split it into test/train datasets and then calculated the MAPE. Another limitation of the model is that it lacks other predictors that could better explain the variance in Y. If we had additional X variables, we could also have used `step` in order to use Akaike's information criteria to select for the best model with maximum Likelihood, *L*.